---
title: "Untitled"
author: "yuhanjin"
date: "2020/2/11"
output: html_document
---

```{r setup, include=FALSE}
library( tidyverse )
library( haven )
library( lmtest )
library( cobalt )
library( sandwich )
library(dplyr) 
library(knitr)
library(plm)
```


```{r}
og_data <- read_dta( "CHDV_30102_ECLS-K_class_size.dta" )


anal_data <- og_data

summary(anal_data)

```

```{r}
# Drop treatment and outcome missingness
anal_data <- filter( anal_data, !is.na( A4CLSIZE ), !is.na( C4RRSCAL ), !C4RRSCAL %in% c( -1, -9 ) )

# deal with the missingness 
anal_data$RACE_MISS <- ifelse( anal_data$RACE %in% c( -1, -9 ), 1, 0 )
anal_data$C1RRSCAL_MISS <- ifelse( anal_data$C1RRSCAL %in% c( -1, -9 ), 1, 0 )
anal_data$C2RRSCAL_MISS <- ifelse( anal_data$C2RRSCAL %in% c( -1, -9 ), 1, 0 )
anal_data$B4YRSTC_MISS <- ifelse( anal_data$B4YRSTC %in% c( -1, -9 ), 1, 0 )

# create a six-category variable “race6”
anal_data$RACE6 <- ifelse(anal_data$RACE == 3 | anal_data$RACE == 4, 3,
                          ifelse(anal_data$RACE == 5 | anal_data$RACE == 6, 4,
                                 ifelse(anal_data$RACE == 7,5,
                                        ifelse(anal_data$RACE == 8 | anal_data$RACE == -9, 6,
                                               anal_data$RACE))))


anal_data$RACE <- ifelse( anal_data$RACE_MISS == 1, 1, anal_data$RACE)
anal_data$C1RRSCAL <- ifelse( anal_data$C1RRSCAL_MISS == 1,
                              mean( filter( anal_data, C1RRSCAL_MISS != 1 )$C1RRSCAL, na.rm = T ),
                              anal_data$C1RRSCAL )
anal_data$C2RRSCAL <- ifelse( anal_data$C2RRSCAL_MISS == 1,
                              mean( filter(anal_data, C2RRSCAL_MISS != 1 )$C2RRSCAL, na.rm = T ),
                              anal_data$C2RRSCAL )
anal_data$B4YRSTC <- ifelse( anal_data$B4YRSTC_MISS == 1,
                              mean( filter(anal_data, B4YRSTC_MISS != 1 )$B4YRSTC, na.rm = T ),
                              anal_data$B4YRSTC )
anal_data
```

```{r}
anal_data$Z <- as.numeric( anal_data$A4CLSIZE <= 19 )

anal_data$RACE6 <- as.factor(anal_data$RACE6)
```

# Question 1
```{r}
# the mean difference in grade 1 literacy achievement (C4RRSCAL) between students attending small classes 

mean_small <- mean(anal_data$C4RRSCAL[anal_data$Z == 1], 
                   na.rm = TRUE)
mean_small
mean_regular <- mean(anal_data$C4RRSCAL[anal_data$Z == 0], 
                    na.rm = TRUE)
mean_regular 
sample_mean_dif <- mean_small - mean_regular
sample_mean_dif


pooled_data <- pdata.frame( anal_data, index = c( "s4_id" ), row.names = F )

# Pooled regression results with clustered standard errors (not Hube  r White)
simple.model <- plm( C4RRSCAL ~ Z, data = pooled_data, model = "pooling" )
summary( simple.model, robust = T )
  
# Calculate variance covariance matrix for Huber-White robust errors
G <- length( unique( pooled_data$s4_id ) )
N <- length( pooled_data$s4_id )
dfa <- ( G / ( G - 1 ) ) * ( N - 1 ) / simple.model$df.residual
pooled_vcov <- dfa * vcovHC( simple.model, cluster = "group", adjust = T )

# Coefficient test
coeftest( simple.model, vcov = pooled_vcov )
# Wald test
waldtest( simple.model, vcov = pooled_vcov, test = "F" )
# Compute effect size of treatment by calculating SD of control group
(control_sd <- sd( anal_data[ anal_data$Z == 0, ]$C4RRSCAL ))
(eff_size <- simple.model$coefficients[ 2 ] / control_sd)
```
# Question 2 
```{r}

```


# Question 3 
```{r}
# decide whether the propensity score model should include the linear and quadratic terms of a covariate
# calculate the variance of covariates of the treated group and the control group 
# C1RRSCAL
(C1RRSCAL_Var_control <- var(anal_data$C1RRSCAL[anal_data$Z == 0], na.rm = T))
(C1RRSCAL_Var_treated <- var(anal_data$C1RRSCAL[anal_data$Z == 1], na.rm = T))
# C2RRSCAL
(C2RRSCAL_Var_control <- var(anal_data$C2RRSCAL[anal_data$Z == 0], na.rm = T))
(C2RRSCAL_Var_treated <- var(anal_data$C2RRSCAL[anal_data$Z == 1], na.rm = T))
# B4YRSTC
(B4YRSTC_Var_control <- var(anal_data$B4YRSTC[anal_data$Z == 0], na.rm = T))
(B4YRSTC_Var_treated <- var(anal_data$B4YRSTC[anal_data$Z == 1], na.rm = T))
```

```{r}
#check if the model should include the product of two covariates if their correlation is different between the treated group and the control group
# C1RRSCAL and C2RRSCAL
(C1RRSCAL_C2RRSCAL_control <- cor(!is.na(anal_data$C1RRSCAL[anal_data$Z == 0]), !is.na(anal_data$C2RRSCAL[anal_data$Z == 0])))
(C1RRSCAL_C2RRSCAL_treated <- cor(!is.na(anal_data$C1RRSCAL[anal_data$Z == 1]), !is.na(anal_data$C2RRSCAL[anal_data$Z == 1])))

# C1RRSCAL and B4YRSTC
(C1RRSCAL_B4YRSTC_control <- cor(!is.na(anal_data$C1RRSCAL[anal_data$Z == 0]), !is.na(anal_data$B4YRSTC[anal_data$Z == 0])))
(C1RRSCAL_B4YRSTC_treated <- cor(!is.na(anal_data$C1RRSCAL[anal_data$Z == 1]), !is.na(anal_data$B4YRSTC[anal_data$Z == 1])))

# C2RRSCAL and B4YRSTC
(C2RRSCAL_B4YRSTC_control <- cor(!is.na(anal_data$C2RRSCAL[anal_data$Z == 0]), !is.na(anal_data$B4YRSTC[anal_data$Z == 0])))
(C2RRSCAL_B4YRSTC_treated <- cor(!is.na(anal_data$C2RRSCAL[anal_data$Z == 1]), !is.na(anal_data$B4YRSTC[anal_data$Z == 1])))

# 
(C1RRSCAL_C2RRSCAL_control <- cor(!is.na(anal_data$GENDER[anal_data$Z == 0]), !is.na(anal_data$RACE6[anal_data$Z == 0])))
(C1RRSCAL_C2RRSCAL_treated <- cor(!is.na(anal_data$GENDER[anal_data$Z == 1]), !is.na(anal_data$RACE6[anal_data$Z == 1])))

```

```{r}
# add square terms 
anal_data$C1RRSCAL_SQ <- ( anal_data$C1RRSCAL )^2
anal_data$C2RRSCAL_SQ <- ( anal_data$C2RRSCAL )^2
anal_data$B4YRSTC_SQ <- ( anal_data$B4YRSTC )^2

# add product terms 
anal_data$C1RRSCAL_C2RRSCAL <- anal_data$C1RRSCAL * anal_data$C2RRSCAL
anal_data$C1RRSCAL_B4YRSTC <- anal_data$C1RRSCAL *  anal_data$B4YRSTC 
```



```{r}
## STEP 2: BUILD A LOGISTIC REGRESSION MODEL

prop.model <- glm( Z ~  RACE6  + C1RRSCAL  + C1RRSCAL_SQ + C1RRSCAL_MISS + 
                        C2RRSCAL  + C2RRSCAL_SQ + C2RRSCAL_MISS + B4YRSTC + B4YRSTC_SQ + B4YRSTC_MISS + RACE_MISS + C1RRSCAL:C2RRSCAL + C1RRSCAL:B4YRSTC                           + RACE6:C2RRSCAL + RACE6:B4YRSTC,
                   family = binomial( link = "logit" ), data = anal_data )
summary( prop.model )

# Given this regression, we're not going to get logit scores with some of our NA categories
anal_data1 <- filter( anal_data, !is.na( C1RRSCAL ), !is.na( C2RRSCAL ), !is.na( B4YRSTC ) )

# Logit Scores
anal_data1$logit <- predict( prop.model, type = "link" )

# Probability of Treatment
anal_data1$pred <- predict( prop.model, type = "response" )
```


```{r}
## STEP 3: IDENTIFY THE COMMON SUPPORT

ggplot(anal_data1 ) +
  geom_histogram( aes( x = logit, fill = factor( Z ) ), alpha = 0.5 )
ggplot( filter( anal_data1, Z == 0 ) ) +
  geom_histogram( aes( x = logit ) )
ggplot( filter( anal_data1, Z == 1 ) ) +
  geom_histogram( aes( x = logit ) )
ggplot( anal_data1 ) +
  geom_density( aes( x = logit, color = factor( Z ) ), alpha = 0.5 )

summary( filter( anal_data1, Z == 0 )$logit )
summary( filter( anal_data1, Z == 1 )$logit )


# Set the calipers and find common support
min_treat <- min( anal_data1[ anal_data1$Z == 1, ]$logit )
min_cont <- min( anal_data1[ anal_data1$Z == 0, ]$logit )
max_treat <- max( anal_data1[ anal_data1$Z == 1, ]$logit )
max_cont <- max( anal_data1[ anal_data1$Z == 0, ]$logit )
caliper <- 0.2 * sd( anal_data1$logit ) # Caliper set to 20% of the standard deviation

anal_data2 <- anal_data1[ anal_data1$logit > max( min_treat, min_cont ) - caliper &
                          anal_data1$logit < min( max_treat, max_cont ) - caliper, ]


ggplot(anal_data2) +
  geom_density(aes( x = logit, color = factor( Z ) ), alpha = 0.5 )
```
```{r}

```

# Question 4

```{r}
treat_data <- anal_data2[anal_data2$Z == 1, ]
treat_data$id <- seq( 1, nrow( treat_data), by = 1)
cont_data <- anal_data2[ anal_data2$Z == 0, ]
matched_data <- treat_data
# For every treated unit, find the matched unit with the closest logit value
for( i in 1:nrow( treat_data ) ) {
  logit_val <- treat_data[ i, ]$logit
  data_id <- treat_data[ i, ]$id
  closest <- min( abs( logit_val - cont_data$logit ) )
  index <- which( abs( logit_val - cont_data$logit ) == closest )
  match <- cont_data[ index[ 1 ], ]
  match$id <- data_id
  matched_data <- rbind( matched_data, match )
}
```



```{r}
## STEP 5: CHECK BALANCE

# Checking Balance on logit
ggplot( matched_data, aes( x = logit, fill = factor( Z ) ) ) +
  geom_histogram( binwidth = 0.5, position = "dodge" )
ggplot( matched_data, aes( x = logit, color = factor( Z ) ) ) +
  geom_density( alpha = 0.2 )
t.test( matched_data$logit ~ matched_data$Z )
summary( lm( logit ~ Z, data = matched_data ) )

# Checking Balance on Covariates


#RACE 
ggplot( matched_data, aes( x = RACE , fill = factor( Z )) ) +
  geom_histogram( binwidth = 0.5, position = "dodge")
ggplot( matched_data, aes( x = RACE , color = factor( Z ) ) ) +
  geom_density( alpha = 0.2)
t.test( matched_data$RACE ~ matched_data$Z )


#C1RRSCAL
ggplot( matched_data, aes( x = C1RRSCAL , fill = factor( Z ) ) ) +
  geom_histogram( binwidth = 0.5, position = "dodge" )
ggplot( matched_data, aes( x = C1RRSCAL , color = factor( Z ) ) ) +
  geom_density( alpha = 0.2 )
t.test( matched_data$C1RRSCAL  ~ matched_data$Z )

#C2RRSCAL
ggplot( matched_data, aes( x = C2RRSCAL , fill = factor( Z ) ) ) +
  geom_histogram( binwidth = 0.5, position = "dodge" )
ggplot( matched_data, aes( x = C2RRSCAL , color = factor( Z ) ) ) +
  geom_density( alpha = 0.2 )
t.test( matched_data$C2RRSCAL  ~ matched_data$Z )

#B4YRSTC
ggplot( matched_data, aes( x = B4YRSTC , fill = factor( Z ) ) ) +
  geom_histogram( binwidth = 0.5, position = "dodge" )
ggplot( matched_data, aes( x = B4YRSTC , color = factor( Z ) ) ) +
  geom_density( alpha = 0.2 )
t.test( matched_data$B4YRSTC  ~ matched_data$Z)

#C1RRSCAL_SQ
ggplot( matched_data, aes( x = C1RRSCAL_SQ , fill = factor( Z ) ) ) +
  geom_histogram( binwidth = 0.5, position = "dodge" )
ggplot( matched_data, aes( x = C1RRSCAL_SQ , color = factor( Z ) ) ) +
  geom_density( alpha = 0.2 )
t.test( matched_data$C1RRSCAL_SQ  ~ matched_data$Z)

#C2RRSCAL_SQ
ggplot( matched_data, aes( x = C2RRSCAL_SQ , fill = factor( Z ) ) ) +
  geom_histogram( binwidth = 0.5, position = "dodge" )
ggplot( matched_data, aes( x = C2RRSCAL_SQ , color = factor( Z ) ) ) +
  geom_density( alpha = 0.2 )
t.test( matched_data$C2RRSCAL_SQ  ~ matched_data$Z)

#B4YRSTC_SQ
ggplot( matched_data, aes( x = B4YRSTC_SQ , fill = factor( Z ) ) ) +
  geom_histogram( binwidth = 0.5, position = "dodge" )
ggplot( matched_data, aes( x = B4YRSTC_SQ , color = factor( Z ) ) ) +
  geom_density( alpha = 0.2 )
t.test( matched_data$B4YRSTC_SQ  ~ matched_data$Z)

#C1RRSCAL_C2RRSCAL

t.test( matched_data$C1RRSCAL_C2RRSCAL  ~ matched_data$Z)

#C1RRSCAL_B4YRSTC

t.test( matched_data$C1RRSCAL_B4YRSTC  ~ matched_data$Z)

#RACE_MISS
ggplot( matched_data, aes( x = RACE_MISS , fill = factor( Z ) ) ) +
  geom_histogram( binwidth = 0.5, position = "dodge" )
ggplot( matched_data, aes( x = RACE_MISS , color = factor( Z ) ) ) +
  geom_density( alpha = 0.2 )
t.test( matched_data$RACE_MISS  ~ matched_data$Z)

#C1RRSCAL_MISS
ggplot( matched_data, aes( x = C1RRSCAL_MISS , fill = factor( Z ) ) ) +
  geom_histogram( binwidth = 0.5, position = "dodge" )
ggplot( matched_data, aes( x = C1RRSCAL_MISS , color = factor( Z ) ) ) +
  geom_density( alpha = 0.2 )
t.test( matched_data$C1RRSCAL_MISS  ~ matched_data$Z)

#C2RRSCAL_MISS
ggplot( matched_data, aes( x = C2RRSCAL_MISS , fill = factor( Z ) ) ) +
  geom_histogram( binwidth = 0.5, position = "dodge" )
ggplot( matched_data, aes( x = C2RRSCAL_MISS , color = factor( Z ) ) ) +
  geom_density( alpha = 0.2 )
t.test( matched_data$C2RRSCAL_MISS  ~ matched_data$Z)

# B4YRSTC_MISS
ggplot( matched_data, aes( x = B4YRSTC_MISS , fill = factor( Z ) ) ) +
  geom_histogram( binwidth = 0.5, position = "dodge" )
ggplot( matched_data, aes( x = B4YRSTC_MISS , color = factor( Z ) ) ) +
  geom_density( alpha = 0.2 )
t.test( matched_data$B4YRSTC_MISS  ~ matched_data$Z)
```

```{r}
# compare the standardized difference and the variance ratio before and after matching
bal.tab(Z ~  RACE6 + RACE_MISS + C1RRSCAL + C1RRSCAL_SQ + C1RRSCAL_MISS + C2RRSCAL + C2RRSCAL_SQ + C2RRSCAL_MISS + B4YRSTC + B4YRSTC_SQ + B4YRSTC_MISS +              C1RRSCAL:C2RRSCAL + C1RRSCAL:B4YRSTC + RACE6:C2RRSCAL + RACE6:B4YRSTC,
        data = anal_data1, estimand = "ATE", m.threshold = 0.1,
        disp.v.ratio = TRUE)
bal.tab(Z ~  RACE6 + RACE_MISS + C1RRSCAL + C1RRSCAL_SQ + C1RRSCAL_MISS + C2RRSCAL + C2RRSCAL_SQ + C2RRSCAL_MISS + B4YRSTC + B4YRSTC_SQ + B4YRSTC_MISS +              C1RRSCAL:C2RRSCAL + C1RRSCAL:B4YRSTC + RACE6:C2RRSCAL + RACE6:B4YRSTC,
        data = matched_data, estimand = "ATE", m.threshold = 0.1,
        disp.v.ratio = TRUE)
```



```{r}
# use the matched sample to estimate the effect of class size type on grade 1 literacy achievement.
ate.m <- lm( C4RRSCAL ~ Z, data = matched_data )
( test <- coeftest( ate.m, vcov = vcovHC( ate.m ) ) )


pooled_data1 <- pdata.frame( matched_data, index = c( "s4_id" ), row.names = F )

# Pooled regression results with clustered standard errors (not Hube  r White)
simple.model <- plm( C4RRSCAL ~ Z, data = pooled_data1, model = "pooling" )
summary( ate.m, robust = T )
  
# Calculate variance covariance matrix for Huber-White robust errors
G <- length( unique( pooled_data1$s4_id ) )
N <- length( pooled_data1$s4_id )
dfa <- ( G / ( G - 1 ) ) * ( N - 1 ) / ate.m$df.residual
pooled_vcov <- dfa * vcovHC( ate.m, cluster = "group", adjust = T )

# Coefficient test
coeftest( ate.m, vcov = vcovHC( ate.m ) )
# Wald test
waldtest( ate.m, vcov = vcovHC( ate.m ), test = "F" )

# Compute effect size of treatment by calculating SD of control group
(control_sd1 <- sd( matched_data[ matched_data$Z == 0, ]$C4RRSCAL ))
(eff_size1 <- ate.m$coefficients[ 2 ] / control_sd)
```
#Question 6 

```{r}
# STEP 4: CALCULATE WEIGHTS
# Assign ATE weights
anal_data2$W_ATE <- ifelse( anal_data2$Z == 1, mean( anal_data2$Z ) / anal_data2$pred,
                           ( 1 - mean( anal_data2$Z ) ) / ( 1 - anal_data2$pred ) )

# Assign ATT weights
anal_data2$W_ATT <- ifelse( anal_data2$Z == 1, 1, ( ( 1 - mean( anal_data2$Z ) ) / mean( anal_data2$Z ) ) *
                             ( anal_data2$pred / ( 1 - anal_data2$pred ) ) )




## STEP 5: CHECK CONVERGENCE
mean( anal_data2$W_ATE )
mean( anal_data2$W_ATT )
```




```{r}
# Balance on logit
summary( lm( logit ~ Z, weights = W_ATE, data = anal_data2 ) )
summary( lm( logit ~ Z, weights = W_ATT, data = anal_data2 ) )
```

```{r}
# Balance on covariates (ATE)
  # Discrete covariates
summary( glm( I( RACE6 == 1 ) ~ Z, weights = W_ATE, data = anal_data2, family = "binomial" ) )
  # Continuous covariates
summary( lm( C1RRSCAL ~ Z, weights = W_ATE, data = anal_data2 ) )

summary( lm( C2RRSCAL ~ Z, weights = W_ATE, data = anal_data2 ) )

summary( lm( B4YRSTC ~ Z, weights = W_ATE, data = anal_data2 ) )

summary( lm( C1RRSCAL_SQ ~ Z, weights = W_ATE, data = anal_data2 ) )

summary( lm( C2RRSCAL_SQ ~ Z, weights = W_ATE, data = anal_data2 ) )

summary( lm( B4YRSTC_SQ ~ Z, weights = W_ATE, data = anal_data2 ) )
 # missingness variables 
summary( lm( RACE_MISS ~ Z, weights = W_ATE, data = anal_data2 ) )

summary( lm( C1RRSCAL_MISS ~ Z, weights = W_ATE, data = anal_data2 ) )

summary( lm( C2RRSCAL_MISS ~ Z, weights = W_ATE, data = anal_data2 ) )

summary( lm( B4YRSTC_MISS ~ Z, weights = W_ATE, data = anal_data2 ) )

# Balance on covariates (ATT)
  # Discrete covariates
summary( glm( I( RACE6 == 1 ) ~ Z, weights = W_ATT, data = anal_data2, family = "binomial" ) )
  # Continuous covariates
summary( lm( C1RRSCAL ~ Z, weights = W_ATT, data = anal_data2 ) )

summary( lm( C2RRSCAL ~ Z, weights = W_ATT, data = anal_data2 ) )

summary( lm( B4YRSTC ~ Z, weights = W_ATT, data = anal_data2 ) )

summary( lm( C1RRSCAL_SQ ~ Z, weights = W_ATT, data = anal_data2 ) )

summary( lm( C2RRSCAL_SQ ~ Z, weights = W_ATT, data = anal_data2 ) )

summary( lm( B4YRSTC_SQ ~ Z, weights = W_ATT, data = anal_data2 ) )
 # missingness variables 
summary( lm( RACE_MISS ~ Z, weights = W_ATT, data = anal_data2 ) )

summary( lm( C1RRSCAL_MISS ~ Z, weights = W_ATT, data = anal_data2 ) )

summary( lm( C2RRSCAL_MISS ~ Z, weights = W_ATT, data = anal_data2 ) )

summary( lm( B4YRSTC_MISS ~ Z, weights = W_ATT, data = anal_data2 ) )
```


```{r}
# Variance Ratios

# the variance ratio before weighting (ATE)
bal.tab( Z ~ RACE6 + RACE_MISS + C1RRSCAL + C1RRSCAL_SQ + C1RRSCAL_MISS +
             C2RRSCAL + C2RRSCAL_SQ + C2RRSCAL_MISS + B4YRSTC + B4YRSTC_SQ + B4YRSTC_MISS + C1RRSCAL:C2RRSCAL + C1RRSCAL:B4YRSTC + 
             RACE6:C2RRSCAL + RACE6:B4YRSTC,
         data = anal_data2, estimand = "ATE", m.threshold = 0.05,
         disp.v.ratio = TRUE )
# After weighting (ATE)
bal.tab( Z ~ RACE6 + RACE_MISS + C1RRSCAL + C1RRSCAL_SQ + C1RRSCAL_MISS +
             C2RRSCAL + C2RRSCAL_SQ + C2RRSCAL_MISS + B4YRSTC + B4YRSTC_SQ + B4YRSTC_MISS + C1RRSCAL:C2RRSCAL + C1RRSCAL:B4YRSTC + 
             RACE6:C2RRSCAL + RACE6:B4YRSTC,
         data = anal_data2, estimand = "ATE", m.threshold = 0.05,
         disp.v.ratio = TRUE, weights = anal_data2$W_ATE, method = "weighting" )

# the variance ratio before weighting (ATT)
bal.tab( Z ~ RACE6 + RACE_MISS + C1RRSCAL + C1RRSCAL_SQ + C1RRSCAL_MISS +
             C2RRSCAL + C2RRSCAL_SQ + C2RRSCAL_MISS + B4YRSTC + B4YRSTC_SQ + B4YRSTC_MISS + C1RRSCAL:C2RRSCAL + C1RRSCAL:B4YRSTC + 
             RACE6:C2RRSCAL + RACE6:B4YRSTC,
         data = anal_data2, estimand = "ATT", m.threshold = 0.05,
         disp.v.ratio = TRUE )
# After weighting (ATT)
bal.tab( Z ~ RACE6 + RACE_MISS + C1RRSCAL + C1RRSCAL_SQ + C1RRSCAL_MISS +
             C2RRSCAL + C2RRSCAL_SQ + C2RRSCAL_MISS + B4YRSTC + B4YRSTC_SQ + B4YRSTC_MISS + C1RRSCAL:C2RRSCAL + C1RRSCAL:B4YRSTC + 
             RACE6:C2RRSCAL + RACE6:B4YRSTC,
         data = anal_data2, estimand = "ATT", m.threshold = 0.05,
         disp.v.ratio = TRUE, weights = anal_data2$W_ATT, method = "weighting" )
```

```{r}
## STEP 7: ESTIMATE THE EFFECT

ate.m <- lm( C4RRSCAL ~ Z, weights = W_ATE, data = anal_data2 )
( test <- coeftest( ate.m, vcov = vcovHC( ate.m ) ) )

att.m <- lm( C4RRSCAL ~ Z, weights = W_ATT, data = anal_data2 )
( test <- coeftest( att.m, vcov = vcovHC( att.m ) ) )

```

```{r}
# use the matched sample to estimate the effect of class size type on grade 1 literacy achievement (ATT).
att.m <- lm( C4RRSCAL ~ Z, weights = W_ATT, data = anal_data2 )
( test <- coeftest( att.m, vcov = vcovHC( att.m ) ) )


pooled_data2 <- pdata.frame( anal_data2, index = c( "s4_id" ), row.names = F )

# Pooled regression results with clustered standard errors (not Hube  r White)
simple.model <- plm( C4RRSCAL ~ Z, data = pooled_data2, model = "pooling" )
summary( att.m, robust = T )
  
# Calculate variance covariance matrix for Huber-White robust errors
G <- length( unique( pooled_data2$s4_id ) )
N <- length( pooled_data2$s4_id )
dfa <- ( G / ( G - 1 ) ) * ( N - 1 ) / att.m$df.residual
pooled_vcov <- dfa * vcovHC( att.m, cluster = "group", adjust = T )

# Coefficient test
coeftest( att.m, vcov = vcovHC( att.m ) )
# Wald test
waldtest( att.m, vcov = vcovHC( att.m ), test = "F" )

# Compute effect size of treatment by calculating SD of control group
(control_sd2 <- sd( anal_data2[ anal_data2$Z == 0, ]$C4RRSCAL ))
(eff_size2 <- att.m$coefficients[ 2 ] / control_sd)
```
```{r}
# use the matched sample to estimate the effect of class size type on grade 1 literacy achievement (ATE).
ate.m <- lm( C4RRSCAL ~ Z, weights = W_ATE, data = anal_data2 )
( test <- coeftest( att.m, vcov = vcovHC( ate.m ) ) )


pooled_data2 <- pdata.frame( anal_data2, index = c( "s4_id" ), row.names = F )

# Pooled regression results with clustered standard errors (not Hube  r White)
simple.model <- plm( C4RRSCAL ~ Z, data = pooled_data2, model = "pooling" )
summary( ate.m, robust = T )
  
# Calculate variance covariance matrix for Huber-White robust errors
G <- length( unique( pooled_data2$s4_id ) )
N <- length( pooled_data2$s4_id )
dfa <- ( G / ( G - 1 ) ) * ( N - 1 ) / ate.m$df.residual
pooled_vcov <- dfa * vcovHC( ate.m, cluster = "group", adjust = T )

# Coefficient test
coeftest( ate.m, vcov = vcovHC( ate.m ) )
# Wald test
waldtest( ate.m, vcov = vcovHC( ate.m ), test = "F" )

# Compute effect size of treatment by calculating SD of control group
(control_sd2 <- sd( anal_data2[ anal_data2$Z == 0, ]$C4RRSCAL ))
(eff_size2 <- ate.m$coefficients[ 2 ] / control_sd)
```

# Question 7
```{r}
# Create data for MMWS

mmws_data <- arrange( anal_data2, CHILDID, C4RRSCAL, Z, RACE6, RACE_MISS, C1RRSCAL, C1RRSCAL_SQ,
                      C1RRSCAL_MISS, C2RRSCAL, C2RRSCAL_SQ, C2RRSCAL_MISS, B4YRSTC, B4YRSTC_SQ, B4YRSTC_MISS, C1RRSCAL_C2RRSCAL, C1RRSCAL_B4YRSTC )
mmws_data <- select( mmws_data, CHILDID, C4RRSCAL, Z, RACE6, RACE_MISS, C1RRSCAL, C1RRSCAL_SQ,
                      C1RRSCAL_MISS, C2RRSCAL, C2RRSCAL_SQ, C2RRSCAL_MISS, B4YRSTC, B4YRSTC_SQ, B4YRSTC_MISS, C1RRSCAL_C2RRSCAL, C1RRSCAL_B4YRSTC )
write_dta( mmws_data, path = "mmws_data.dta", version = 12 )

# Read in data from MMWS
mmws_results <- read_dta( "post_mmws.dta" )

# Estimated effect
mmws.m <- lm( C4RRSCAL ~ Z, weights = mmws_wgt, data = mmws_results )
( test <- coeftest( mmws.m, vcov = vcovHC( mmws.m ) ) )

  # For fun, what if we did it just like propensity scores
mmws.m <- lm( C4RRSCAL ~ Z + factor( stratum ), data = mmws_results )
( test <- coeftest( mmws.m, vcov = vcovHC( mmws.m ) ) )
```


